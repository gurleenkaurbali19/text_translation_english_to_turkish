{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "be16b3c530704fb393d17e8ce3a99c68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4139e6aa646047b7815f9111fcda9574",
              "IPY_MODEL_b7dd79aebe8943b1893025a7cf39caa3",
              "IPY_MODEL_070b77dbf64d493988a3121dd8ede614"
            ],
            "layout": "IPY_MODEL_a6e666c45cf747f7a97d7631bb90e907"
          }
        },
        "4139e6aa646047b7815f9111fcda9574": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc9d4bb51d0b4f89b320407f0854446b",
            "placeholder": "​",
            "style": "IPY_MODEL_07089766af5a4dca980561c6268bb3c3",
            "value": "Batches: 100%"
          }
        },
        "b7dd79aebe8943b1893025a7cf39caa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c1a667946de443dbf148f00d6da469d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f66e030ff384e7483d3fd636beacad9",
            "value": 1
          }
        },
        "070b77dbf64d493988a3121dd8ede614": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8a3251361554aea95df25c348bb7738",
            "placeholder": "​",
            "style": "IPY_MODEL_4e43c55f26344201a78e84d75407fe01",
            "value": " 1/1 [00:02&lt;00:00,  2.05s/it]"
          }
        },
        "a6e666c45cf747f7a97d7631bb90e907": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc9d4bb51d0b4f89b320407f0854446b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07089766af5a4dca980561c6268bb3c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c1a667946de443dbf148f00d6da469d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f66e030ff384e7483d3fd636beacad9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8a3251361554aea95df25c348bb7738": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e43c55f26344201a78e84d75407fe01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n",
        "\n",
        "model_name = \"facebook/m2m100_418M\"\n",
        "tokenizer = M2M100Tokenizer.from_pretrained(model_name)\n",
        "model = M2M100ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "def translate_m2m100(english_text, src_lang=\"en\", tgt_lang=\"tr\"):\n",
        "    tokenizer.src_lang = src_lang\n",
        "    inputs = tokenizer(english_text, return_tensors=\"pt\", padding=True)\n",
        "    generated_tokens = model.generate(**inputs, forced_bos_token_id=tokenizer.get_lang_id(tgt_lang))\n",
        "    return tokenizer.decode(generated_tokens[0], skip_special_tokens=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZZ3bmOoG3stI"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_text = \"okay\"\n",
        "turkish_translation = translate_m2m100(english_text)\n",
        "print(f\"English: {english_text}\")\n",
        "print(f\"Turkish: {turkish_translation}\")"
      ],
      "metadata": {
        "id": "IUR9LG_T3v1P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c215857b-d0b6-4ccf-cc86-809c2180e646"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English: okay\n",
            "Turkish: Tamam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_file(input_file, output_file, src_lang=\"en\", tgt_lang=\"tr\"):\n",
        "    with open(input_file, 'r', encoding='utf-8') as f:\n",
        "        lines = f.readlines()  # Read file line by line to preserve formatting\n",
        "\n",
        "    translated_lines = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Translate only non-empty lines\n",
        "            translated_line = translate_m2m100(line.strip(), src_lang, tgt_lang)\n",
        "            translated_lines.append(translated_line)\n",
        "        else:\n",
        "            translated_lines.append(\"\")  # Preserve blank lines\n",
        "\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        f.write(\"\\n\".join(translated_lines))  # Join lines back with newline characters\n",
        "\n",
        "    print(f\"Translation saved to {output_file}\")\n",
        "\n",
        "translate_file(\"/content/sample_data/input.txt\", \"translated_output.txt\", \"en\", \"tr\")"
      ],
      "metadata": {
        "id": "e8hVTHgrE6Ln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f077fdd-ff56-4942-fd05-8a9567d1e2c3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translation saved to translated_output.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vVjSSHbSOE7j"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af37v-HYIRbB",
        "outputId": "8e5d1e2f-865a-40d1-8d13-07ac937defd6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfplumber\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWPGl1Zu3cqO",
        "outputId": "8d95213c-4750-4b2e-aa95-e2fe38b6f8d3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.11/dist-packages (0.11.5)\n",
            "Requirement already satisfied: pdfminer.six==20231228 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (20231228)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.1.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (4.30.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "\n",
        "def extract_text_from_pdf(pdf_path, output_txt):\n",
        "    \"\"\"Extracts text from a PDF and saves it to an intermediate text file while preserving formatting.\"\"\"\n",
        "    text = \"\"\n",
        "\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page_num, page in enumerate(pdf.pages, start=1):\n",
        "            extracted_text = page.extract_text()\n",
        "            if extracted_text:\n",
        "                # Preserve page breaks for clarity\n",
        "                text += f\"\\n--- Page {page_num} ---\\n{extracted_text}\\n\"\n",
        "            else:\n",
        "                text += f\"\\n--- Page {page_num} (No text extracted) ---\\n\"\n",
        "\n",
        "    if not text.strip():\n",
        "        print(\"No extractable text found in the PDF.\")\n",
        "        return None\n",
        "\n",
        "    # Save extracted text to a file\n",
        "    with open(output_txt, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(text)\n",
        "\n",
        "    print(f\"Extracted text saved to {output_txt}\")\n",
        "    return output_txt\n",
        "\n",
        "# Example usage\n",
        "pdf_path = \"/content/sample_data/Customer_sentiment_analysis_synopsis.pdf\"\n",
        "output_txt = \"extracted_text.txt\"\n",
        "extract_text_from_pdf(pdf_path, output_txt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "sa_6xxLnHe_L",
        "outputId": "be555f8a-148c-4001-97f6-7483f4b43427"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted text saved to extracted_text.txt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'extracted_text.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"extracted_text.txt\", 'r', encoding=\"utf-8\") as f:\n",
        "    extracted_text = f.read()\n",
        "    print(extracted_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvXz8LP8He44",
        "outputId": "db3919fb-4f6c-4a2e-8af7-a5d1e034ac91"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Page 1 ---\n",
            "Guru Gobind Singh Indraprastha University\n",
            "CUSTOMER SENTIMENT AND FEEDBACK ANALYSIS\n",
            "MAJOR PROJECT SYNOPSIS\n",
            "Submitted by: Submitted to:\n",
            "Name: MS. Kanika\n",
            "Gurleen Kaur Bali\n",
            "Roll Number:\n",
            "03290302022\n",
            "Course and section: BCA M1\n",
            "\n",
            "--- Page 2 ---\n",
            "Gurleen Kaur Bali 03290302022 Major Project Synopsis\n",
            "SYNOPSIS OF THE PROJECT:\n",
            "Title of the Project:\n",
            "Customer Sentiment and feedback Analysis\n",
            "Statement about the Problem:\n",
            "Customer feedback plays a crucial role in shaping business strategies. With the rise of e-commerce and\n",
            "online platforms, customers frequently leave reviews about products and services. However, manually\n",
            "analysing thousands of reviews is time-consuming and inefficient. Businesses need an automated\n",
            "system to analyse customer sentiments accurately and provide actionable insights. This project aims to\n",
            "develop a sentiment analysis system that classifies customer reviews as positive, negative, or neutral\n",
            "and predicts a corresponding star rating out of 5.\n",
            "Why is the Particular Topic Chosen?\n",
            "With digital transformation, businesses are increasingly relying on customer feedback for decision-\n",
            "making. Traditional methods of analysing reviews are inefficient, and businesses need AI-driven\n",
            "solutions for fast and accurate sentiment assessment. A machine learning-based sentiment analysis\n",
            "system helps companies understand customer perceptions, improve products, and enhance customer\n",
            "satisfaction. This project will leverage natural language processing (NLP) techniques to achieve reliable\n",
            "sentiment classification.\n",
            "Objective and Scope of the Project:\n",
            "Objective:\n",
            "• Develop a sentiment analysis model to classify customer reviews as positive, negative, or\n",
            "neutral.\n",
            "• Predict a star rating (1-5) based on the sentiment.\n",
            "• Provide a user-friendly interface for businesses to input customer reviews and receive\n",
            "sentiment predictions.\n",
            "Scope:\n",
            "• The project focuses on text-based reviews from various platforms.\n",
            "• It will use machine learning or deep learning models to classify sentiments.\n",
            "• An interface will be developed to visualize sentiment analysis results.\n",
            "• The project will enhance customer experience by offering actionable insights.\n",
            "\n",
            "--- Page 3 ---\n",
            "Gurleen Kaur Bali 03290302022 Major Project Synopsis\n",
            "Methodology:\n",
            "1. Data Collection:\n",
            "o Dataset sourced from Hugging Face.\n",
            "o Preprocessing to remove noise, stopwords, and punctuation.\n",
            "2. Data Processing & Feature Engineering:\n",
            "o Tokenization using NLP techniques (spaCy/Keras tokenizer).\n",
            "o Word embeddings\n",
            "3. Model Selection & Training:\n",
            "o Used machine learning classifiers (Logistic Regression, SVM, Random Forest) , deep learning\n",
            "(LSTMs, Transformers).\n",
            "o Fine-tuning and hyperparameter optimization.\n",
            "4. Evaluation & Validation:\n",
            "o Metrics: Accuracy, Precision, Recall, F1-score.\n",
            "o Train-test split and cross-validation.\n",
            "5. Deployment:\n",
            "o Developed a web-based UI.\n",
            "o Allows user to input reviews and receive sentiment classification and ratings.\n",
            "Hardware & Software to be Used:\n",
            "• Hardware:\n",
            "o Standard computing system with GPU (Google Colab for deep learning models).\n",
            "• Software & Libraries:\n",
            "o Python\n",
            "o NLP libraries: spaCy, NLTK, Transformers (Hugging Face)\n",
            "o Machine Learning: Scikit-learn, TensorFlow/PyTorch\n",
            "o Database: SQLite/MySQL\n",
            "Testing Technologies used:\n",
            "• Unit Testing for model validation\n",
            "• Integration Testing for web application\n",
            "• Performance Testing for handling large volumes of reviews\n",
            "• Usability Testing to ensure ease of use for businesses\n",
            "\n",
            "--- Page 4 ---\n",
            "Gurleen Kaur Bali 03290302022 Major Project Synopsis\n",
            "Contribution of the Project:\n",
            "• For Businesses: Provides actionable insights into customer satisfaction.\n",
            "• For Customers: Enhances user experience by identifying issues through sentiment analysis.\n",
            "• For Data Science Community: Contributes to NLP advancements in sentiment classification.\n",
            "• For Future Development: Can be expanded to multilingual sentiment analysis.\n",
            "Process Description:\n",
            "1. User Input: The user enters a review through the web interface.\n",
            "2. Preprocessing: The input is cleaned and tokenized.\n",
            "3. Model Prediction: The sentiment analysis model classifies the review.\n",
            "4. Output: Displays sentiment (Positive/Negative/Neutral) and star rating.\n",
            "Resources and limitations:\n",
            "Resources Required:\n",
            "• Pre-trained sentiment analysis datasets.\n",
            "• Computational resources (Cloud/GPU for deep learning models).\n",
            "• NLP libraries for text processing.\n",
            "Limitations:\n",
            "• Accuracy depends on the quality and diversity of training data.\n",
            "• Sentiment detection may be limited for sarcasm and ambiguous reviews.\n",
            "• Performance may vary across different domains and industries.\n",
            "Conclusion:\n",
            "This project aims to build an AI-powered sentiment analysis system to classify customer reviews and\n",
            "predict ratings. It leverages NLP and machine learning for automated feedback analysis, offering\n",
            "businesses a scalable and data-driven approach to understanding customer sentiment. The innovation\n",
            "lies in using a hybrid approach (ML & deep learning) and providing an intuitive user interface, making\n",
            "it a practical and impactful solution for businesses.\n",
            "\n",
            "--- Page 5 ---\n",
            "Gurleen Kaur Bali 03290302022 Major Project Synopsis\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translate_file(\"extracted_text.txt\", \"translated_output_pdf.txt\", \"en\", \"tr\")\n"
      ],
      "metadata": {
        "id": "rpF3lU_NIEpT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ee01a6a-a4e6-4e1b-e829-bcd16b2b8464"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translation saved to translated_output_pdf.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUxiq1sF2MQ6",
        "outputId": "8737628d-0a3b-4b8e-b670-ad600270d2ee"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting zemberek-python\n",
            "  Downloading zemberek_python-0.2.3-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting antlr4-python3-runtime==4.8 (from zemberek-python)\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from zemberek-python) (1.26.4)\n",
            "Downloading zemberek_python-0.2.3-py3-none-any.whl (95.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.1/95.1 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141214 sha256=2a664e5f5a5a9ea2f9266c87972800b386ab497199bdf3b1194b3f0ec2457681\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/10/be/9a70640a3a60ed4a7e1a45e49bb9f58b04692d5d7b517bd39e\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, zemberek-python\n",
            "Successfully installed antlr4-python3-runtime-4.8 zemberek-python-0.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yytZLMqF2McI",
        "outputId": "dbf2a6a2-d449-4c77-f933-264c7b9e57b0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:zemberek.morphology.turkish_morphology:TurkishMorphology instance initialized in 30.246526956558228\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-02-04 16:55:25,760 - zemberek.morphology.turkish_morphology - INFO\n",
            "Msg: TurkishMorphology instance initialized in 30.246526956558228\n",
            "\n",
            "Corrected text saved to corrected_translated_output_pdf.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForMaskedLM, BertTokenizer\n",
        "import torch\n",
        "import re\n",
        "\n",
        "# Load Turkish BERT model and tokenizer\n",
        "model_name = \"dbmdz/bert-base-turkish-cased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForMaskedLM.from_pretrained(model_name)\n",
        "\n",
        "def preprocess_text(file_path):\n",
        "    \"\"\"\n",
        "    Reads and cleans the translated Turkish text from a file.\n",
        "    \"\"\"\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        text = file.read()\n",
        "\n",
        "    # Remove unwanted characters and normalize spaces\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    text = re.sub(r\"[^\\wşçöğüİıŞÇÖĞÜa-zA-Z.,!? ]\", \"\", text)\n",
        "    text = text.strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "def compute_perplexity(text):\n",
        "    \"\"\"\n",
        "    Computes a score for the text using the BERT Masked Language Model.\n",
        "    This is used as a proxy to assess the fluency of the text.\n",
        "    \"\"\"\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
        "        loss = outputs.loss\n",
        "        perplexity = torch.exp(loss)\n",
        "\n",
        "    return perplexity.item()\n",
        "\n",
        "# Example Usage:\n",
        "file_path = \"translated_output_pdf.txt\"\n",
        "cleaned_text = preprocess_text(file_path)\n",
        "perplexity_score = compute_perplexity(cleaned_text)\n",
        "\n",
        "print(f\"Perplexity Score: {perplexity_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXGDlvPmIE4M",
        "outputId": "9f5d9b1e-297f-48d4-ec5f-b5940de66656"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity Score: 1.4937987327575684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install textstat\n"
      ],
      "metadata": {
        "id": "O4k3O-CTIFBm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3324a91f-3e52-4c70-dc68-6e2c4b41effe"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textstat in /usr/local/lib/python3.11/dist-packages (0.7.4)\n",
            "Requirement already satisfied: pyphen in /usr/local/lib/python3.11/dist-packages (from textstat) (0.17.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from textstat) (75.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textstat\n",
        "\n",
        "def readability_score(text):\n",
        "    score = textstat.flesch_reading_ease(text)\n",
        "    return score\n",
        "\n",
        "def check_readability_of_translated_file(file_path):\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        text = file.read()\n",
        "    score = readability_score(text)\n",
        "    print(f\"Readability Score: {score}\")\n",
        "\n",
        "# Call this function with your file\n",
        "check_readability_of_translated_file('translated_output_pdf.txt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okvVGzulSJ0j",
        "outputId": "7193d33e-71c7-435a-a364-963c4fa7b78a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Readability Score: 40.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8S0Thqj_17ZL"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nmv4ZFIS16yL"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "def check_semantic_similarity(original, translated):\n",
        "    model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')  # Pre-trained multilingual model\n",
        "    embeddings = model.encode([original, translated])\n",
        "    similarity = util.pytorch_cos_sim(embeddings[0], embeddings[1])\n",
        "    return similarity.item()\n",
        "\n",
        "def check_semantic_similarity_of_translated_file(file_path):\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        translated_text = file.read()\n",
        "\n",
        "    # Example original sentence in English\n",
        "    original = \"This is a sample English sentence.\"\n",
        "\n",
        "    similarity_score = check_semantic_similarity(original, translated_text)\n",
        "    print(f\"Semantic Similarity Score: {similarity_score}\")\n",
        "\n",
        "# Call this function with your file\n",
        "check_semantic_similarity_of_translated_file('translated_output_pdf.txt')\n"
      ],
      "metadata": {
        "id": "qonFm-D6Hehw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205,
          "referenced_widgets": [
            "be16b3c530704fb393d17e8ce3a99c68",
            "4139e6aa646047b7815f9111fcda9574",
            "b7dd79aebe8943b1893025a7cf39caa3",
            "070b77dbf64d493988a3121dd8ede614",
            "a6e666c45cf747f7a97d7631bb90e907",
            "fc9d4bb51d0b4f89b320407f0854446b",
            "07089766af5a4dca980561c6268bb3c3",
            "7c1a667946de443dbf148f00d6da469d",
            "5f66e030ff384e7483d3fd636beacad9",
            "c8a3251361554aea95df25c348bb7738",
            "4e43c55f26344201a78e84d75407fe01"
          ]
        },
        "outputId": "5d41e711-6e55-4d49-b425-d1562c289b9c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-02-04 16:55:50,660 - sentence_transformers.SentenceTransformer - INFO\n",
            "Msg: Use pytorch device_name: cpu\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-02-04 16:55:50,667 - sentence_transformers.SentenceTransformer - INFO\n",
            "Msg: Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be16b3c530704fb393d17e8ce3a99c68"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Semantic Similarity Score: 0.10829651355743408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GDZc4qqcHd8p"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7TliXDmcPLmK"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OUwgtFuHQJvG"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q9wtBMa_04Qf"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hf1B_Kg29BXn"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HMPmSBer9Uk4"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jiNuwnZE9aHu"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qACt_wQj9ccE"
      },
      "execution_count": 36,
      "outputs": []
    }
  ]
}